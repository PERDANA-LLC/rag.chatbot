---
phase: 3
plan: 1
wave: 1
depends_on: []
files_modified:
  - supabase/migrations/0002_chat.sql
  - types/supabase.ts
  - app/api/chat/route.ts
  - lib/ai/rag.ts
autonomous: true
user_setup: []

must_haves:
  truths:
    - "New tables: conversations, messages"
    - "API returns RAG answer"
    - "API stores history"
  artifacts:
    - "app/api/chat/route.ts exists"
---

# Plan 3.1: Chat API & Architecture

<objective>
Implement the backend architecture for chatting.
1. Database Schema: `conversations` (session) and `messages` (history).
2. RAG Logic: `retrieveContext` + `generateResponse`.
3. API Endpoint: `POST /api/chat`.

Purpose: specific instructions to enable conversation.
Output: specific instructions to working Chat API.
</objective>

<context>
Load for context:
- .gsd/SPEC.md
- lib/ai/gemini.ts
</context>

<tasks>

<task type="auto">
  <name>Update Schema for Chat</name>
  <files>supabase/migrations/0002_chat.sql, types/supabase.ts</files>
  <action>
    Create new SQL migration:
    - `conversations`: id, chatbot_id, visitor_id (optional), created_at.
    - `messages`: id, conversation_id, role (user/assistant), content, created_at.
    - RLS policies (public insert allowed for public chat?). 
      - **CRITICAL**: Messages RLS must allow 'anon' to insert if they own the conversation (maybe via cookie/session ID matching?). 
      - Simplified approach: secure with Service Role in API for now, or use signed tokens.
      - Let's stick to Server Side API handling all DB Interaction, so RLS can stays strict (Users view own bots' messages).
    
    Update TypeScript definitions.
  </action>
  <verify>ls supabase/migrations</verify>
  <done>Schema updated</done>
</task>

<task type="auto">
  <name>Create RAG Logic</name>
  <files>lib/ai/rag.ts</files>
  <action>
    Implement `RAGService`:
    - `chat(chatbotId, query, history)`:
      1. Fetch chatbot config (system prompt).
      2. Fetch relevant sources (Gemini File Search handles this implicitly via Tools, do we need manual filtering?).
         - Gemini File Search works best attached to a specific Model configuration.
         - *Problem*: Gemini File Search requires uploading files *to the API* but we did that.
         - Do we need to pass *which* files to search? Yes, `tool usage` needs context.
         - *Strategy*: Retreive all `content_uri`s for the chatbot from `knowledge_base_sources`.
      3. Call `GeminiService.generateAnswer` with specific File URIs.
      4. return answer.
  </action>
  <verify>ls lib/ai/rag.ts</verify>
  <done>RAG Logic implemented</done>
</task>

<task type="auto">
  <name>Create Chat Endpoint</name>
  <files>app/api/chat/route.ts</files>
  <action>
    POST endpoint:
    - Body: { chatbotId, message, conversationId (optional) }
    - If no conversationId, create one.
    - Store User Message.
    - Call `RAGService.chat`.
    - Store Assistant Message.
    - Return { conversationId, message }.
    
    *Security*: Validate `chatbotId` exists.
  </action>
  <verify>ls app/api/chat/route.ts</verify>
  <done>Chat API ready</done>
</task>

</tasks>

<verification>
After all tasks, verify:
- [ ] SQL migration applied manually
- [ ] API responds to curl
</verification>
